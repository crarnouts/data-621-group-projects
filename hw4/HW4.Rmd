---
title: "DATA 621 Homework #4"
author: "Critical Thinking Group 3"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    code_folding: "hide"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
require(gridExtra)
library(Amelia)
library(kableExtra)
library(caret)
library(DMwR)
# Thank you Stack Overflow!
# A Prefix nulling hook.

# Make sure to keep the default for normal processing.
default_output_hook <- knitr::knit_hooks$get("output")

# Output hooks handle normal R console output.
knitr::knit_hooks$set( output = function(x, options) {

  comment <- knitr::opts_current$get("comment")
  if( is.na(comment) ) comment <- ""
  can_null <- grepl( paste0( comment, "\\s*\\[\\d?\\]" ),
                     x, perl = TRUE)
  do_null <- isTRUE( knitr::opts_current$get("null_prefix") )
  if( can_null && do_null ) {
    # By default R print output aligns at the right brace.
    align_index <- regexpr( "\\]", x )[1] - 1
    # Two cases: start or newline
    re <- paste0( "^.{", align_index, "}\\]")
    rep <- comment
    x <- gsub( re, rep,  x )
    re <- paste0( "\\\n.{", align_index, "}\\]")
    rep <- paste0( "\n", comment )
    x <- gsub( re, rep,  x )
  }

  default_output_hook( x, options )

})
knitr::opts_template$set("kill_prefix"=list(comment=NA, null_prefix=TRUE))
```

```{r}
df <- read.csv("./data/insurance_training_data.csv") %>%
  mutate(TARGET_FLAG = as.factor(TARGET_FLAG)) %>%
  select(-INDEX)
evaluation <- read.csv("./data/insurance-evaluation-data.csv") %>%
  select(-INDEX)

strip_dollars <- function(x){
  x <- as.character(x)
  x <- gsub(",", "", x)
  x <- gsub("\\$", "", x)
  as.numeric(x)
}

hw4_plot <- function(df, var, strip_dollar_signs = FALSE){
  if(strip_dollar_signs){
    df$X <- strip_dollars(df[[var]])
  } else {
    df$X <- df[[var]]
  }
  plot_1 <- ggplot(df, aes(X, TARGET_FLAG, color = TARGET_FLAG)) +
    geom_jitter() +
    theme_minimal() +
    theme(legend.position = "none",
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  plot_2 <- ggplot(df, aes(X, TARGET_AMT, color = TARGET_FLAG)) +
    geom_point() +
    theme_minimal() +
    theme(legend.position = "none",
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  grid.arrange(plot_1, plot_2, ncol=2)
}

hw4_categorical_plot <- function(df, var, strip_dollar_signs = FALSE){
  if(strip_dollar_signs){
    df$X <- strip_dollars(df[[var]])
  } else {
    df$X <- df[[var]]
  }
  plot_1 <- ggplot(df, aes(X, TARGET_FLAG, color = TARGET_FLAG)) +
    geom_jitter() +
    theme_minimal() +
    theme(legend.position = "none",
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  plot_2 <- df %>%
    filter(TARGET_FLAG == 1) %>%
    ggplot(., aes(X, TARGET_AMT)) +
      geom_boxplot() +
      theme_minimal() +
      theme(legend.position = "none",
            axis.title.x = element_blank(),
            axis.title.y = element_blank())
  
  grid.arrange(plot_1, plot_2, ncol=2)
}
```

## Introduction 

We have been given a dataset with `r nrow(df)` records representing customers of an auto insurance company.  Each record has two response variables.  The first is a binary flag where one means a person was in a car crash and zero means they were not.  There are `r df %>% filter(TARGET_FLAG == 1) %>% nrow()` rows with a one flag and `r df %>% filter(TARGET_FLAG == 0) %>% nrow()` with a zero flag.  
The first objective is to logistic regression classifier to predict if a person was in a car crash.  The second sreponse variable is the amount it will cost if the person crashes their car.  The value is zero if the person did not crash their car.


## Data Exploration

We will first look at the summary statistics for the data

```{r}
df %>%
  summary() %>%
  kable() %>%
  kable_styling()
```

There are some missing values that we will need to deal with.  Let's look at the predictors to see how well they predict if there is an accident (plot on the left) and how much it would cost (plot on the right).  Numeric variables will get scatterplots, while categorical will get box plots

### AGE

**Theoretical Effect**
Very young people tend to be risky.  Maybe very old people also.

```{r} 
hw4_plot(df, "AGE")
```

**Observed Effect**
There is very little information encapsulated in the age of the person.


### BLUEBOOK

**Theoretical Effect**
Unknown effect on probability of collision, but probably effects the payout if there is a crash.

```{r} 
hw4_plot(df, "BLUEBOOK", TRUE)
```

**Observed Effect**
The plot suggests that people with low value and high value vehicles are equally likely to be in a crash.  It also suggests the payout is not strongly correlated with the vehicle's value.

### CAR_AGE

**Theoretical Effect**
Unknown effect on probability of collision, but probably effects the payout if there is a crash.

```{r} 
hw4_plot(df, "CAR_AGE")
```

**Observed Effect**
The plot suggests that people with old or new vehicles are equally likely to be in a crash.  It also suggests the payout is not strongly correlated with the vehicle's age.  *There is an observation with a negative value that will need to be cleaned up.*

### CAR_TYPE

**Theoretical Effect**
Unknown effect on probability of collision, but probably effects the payout if there is a crash.

```{r} 
hw4_categorical_plot(df, "CAR_TYPE")
```

**Observed Effect**
The plot suggests that the type of vehicle has no effect on the probability of being in an accident, and little effect of the cost.




## Data Preparation

### Fix Data Types

There are some variables that are currently factors that are dollar values that need to be transformed into numeric variables.  We will do this to both the `df` and `evaluation` data frames.

```{r}
fix_data_types <- function(messy_df){
  messy_df %>%
    rowwise() %>%
    mutate(INCOME = strip_dollars(INCOME),
           HOME_VAL = strip_dollars(HOME_VAL),
           BLUEBOOK = strip_dollars(BLUEBOOK),
           OLDCLAIM = strip_dollars(OLDCLAIM)) %>%
    ungroup()
}

df <- fix_data_types(df)
evaluation <- fix_data_types(evaluation)
```


```{r}
missmap(df, main = "Missing vs Observed Values")
```

```{r}
df %>%
  summary() %>%
  kable() %>%
  kable_styling()
```

### Fix Missing Values
There are missing values.  We will fill in the missing variables using KNN.

```{r, null_prefix = TRUE}
set.seed(42)
#knn <- df %>%
#  select(-TARGET_FLAG, -TARGET_AMT) %>%
#  na.omit() %>%
#  knnImputation()

for(var in names(df)){
  impute_me <- is.na(df[[var]])
  if (nrow(df[impute_me,]) > 0){
    print(paste("Fixing the", nrow(df[impute_me,]), "missing values in", var, "(df)"))
    #df[impute_me, var] <- knn[impute_me, var] 
  }
}
```

### Feature Creation

We will create a log transformed income and home value feature.  We will also create an average claim amount that will hopefully track better with the `TARGET_AMT` variable.

```{r}
feature_creation <- function(d){
  d %>%
    rowwise() %>%
    mutate(LOG_INCOME = log(INCOME + 1),
           LOG_HOME_VAL = log(HOME_VAL + 1),
           AVG_CLAIM = ifelse(CLM_FREQ > 0, OLDCLAIM / CLM_FREQ, 0)) %>%
    ungroup()
}

df <- feature_creation(df)
evaluation <- feature_creation(evaluation)
```

### Creating Training/Test Data Sets

Now that we have a complete data set we will split the data into a training (`train`) and test set (`test`). We'll use a 70-30 split between train and test, respectively.

```{r}
set.seed(42)
train_index <- createDataPartition(df$TARGET_AMT, p = .7, list = FALSE, times = 1)
train <- df[train_index,]
test <- df[-train_index,]
```