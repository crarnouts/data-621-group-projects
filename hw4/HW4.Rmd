---
title: "DATA 621 Homework #4"
author: "Critical Thinking Group 3"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    code_folding: "hide"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
require(gridExtra)
library(Amelia)
library(kableExtra)
library(caret)
library(DMwR)
library(scales)
library(RColorBrewer)
# Thank you Stack Overflow!
# A Prefix nulling hook.

# Make sure to keep the default for normal processing.
default_output_hook <- knitr::knit_hooks$get("output")

# Output hooks handle normal R console output.
knitr::knit_hooks$set( output = function(x, options) {

  comment <- knitr::opts_current$get("comment")
  if( is.na(comment) ) comment <- ""
  can_null <- grepl( paste0( comment, "\\s*\\[\\d?\\]" ),
                     x, perl = TRUE)
  do_null <- isTRUE( knitr::opts_current$get("null_prefix") )
  if( can_null && do_null ) {
    # By default R print output aligns at the right brace.
    align_index <- regexpr( "\\]", x )[1] - 1
    # Two cases: start or newline
    re <- paste0( "^.{", align_index, "}\\]")
    rep <- comment
    x <- gsub( re, rep,  x )
    re <- paste0( "\\\n.{", align_index, "}\\]")
    rep <- paste0( "\n", comment )
    x <- gsub( re, rep,  x )
  }

  default_output_hook( x, options )

})
knitr::opts_template$set("kill_prefix"=list(comment=NA, null_prefix=TRUE))
```

```{r}
df <- read.csv("./data/insurance_training_data.csv")
evaluation <- read.csv("./data/insurance-evaluation-data.csv")

strip_dollars <- function(x){
  x <- as.character(x)
  x <- gsub(",", "", x)
  x <- gsub("\\$", "", x)
  as.numeric(x)
}
```

## Introduction 

We have been given a dataset with `r nrow(df)` records representing customers of an auto insurance company.  Each record has two response variables.  The first is a binary flag where one means a person was in a car crash and zero means they were not.  There are `r df %>% filter(TARGET_FLAG == 1) %>% nrow()` rows with a one flag and `r df %>% filter(TARGET_FLAG == 0) %>% nrow()` with a zero flag.

```{r, echo=FALSE}
df %>% 
  mutate(TARGET_FLAG = as.factor(TARGET_FLAG)) %>%
  ggplot(aes(x=TARGET_FLAG,fill=TARGET_FLAG)) +
  geom_bar() + scale_y_continuous() + scale_fill_brewer(palette="Set1") +
  theme_light() +
  theme(legend.position = "none") +
  labs(x="TARGET_FLAG", y="# Observations")
```

The first objective is to train a logistic regression classifier to predict if a person was in a car crash.  The second reponse variable is the amount it will cost if the person crashes their car.  The value is zero if the person did not crash their car.

The second objective will be to train a regression model to predict the cost of a crash, if one occurred.  

```{r, echo=FALSE}
df %>% filter(TARGET_FLAG == 1) %>%
  ggplot(aes(x=TARGET_AMT)) + geom_density() +
  geom_vline(aes(xintercept = mean(TARGET_AMT)), lty=2, col="red") +
  geom_label(aes(x=mean(TARGET_AMT),y=1,label="mu"),parse=T) +
  geom_vline(aes(xintercept = median(TARGET_AMT)), lty=2, col="darkgreen") +
  geom_label(aes(x=median(TARGET_AMT),y=.5,label="median")) +
  scale_x_log10(labels=comma) + theme_light() +
  labs(title="TARGET_AMT Density Plot", caption="x-axis is log 10 scale",
       y="Density", x="LOG(TARGET_AMT)")
```

Looking at the distribution of the `TARGET_AMT` variable, we can see that the variable is considerably right-skewed. Thus, a LOG transform might be best here.

## Data Exploration

We will first look at the summary statistics for the data

```{r}
df %>%
  summary() %>%
  kable() %>%
  kable_styling()
```

There are some missing values that we will need to deal with. There are also some values that seem invalid (i.e. -3 CAR_AGE).

## Data Preparation

### Fix Data Types

There are some variables that are currently factors that are dollar values that need to be transformed into numeric variables.  We will do this to both the `df` and `evaluation` data frames.  There are also some invalid data that will be changed to NAs.

```{r}
strip_dollars <- function(x){
  x <- as.character(x)
  x <- gsub(",", "", x)
  x <- gsub("\\$", "", x)
  as.numeric(x)
}

fix_data_types <- function(messy_df){
  messy_df %>%
    rowwise() %>%
    mutate(INCOME = strip_dollars(INCOME),
           HOME_VAL = strip_dollars(HOME_VAL),
           BLUEBOOK = strip_dollars(BLUEBOOK),
           OLDCLAIM = strip_dollars(OLDCLAIM)) %>%
    ungroup()
}

na_bad_values <- function(messy_df){
  messy_df %>%
    rowwise() %>%
    mutate(CAR_AGE = ifelse(CAR_AGE < 0, NA, CAR_AGE))%>%
    ungroup()
}

df <- df %>%
  fix_data_types() %>%
  na_bad_values()
evaluation <- evaluation %>%
  fix_data_types() %>%
  na_bad_values()
```

Now that we have fixed the variables, we can look at a sumamry of the data:

```{r}
df %>%
  summary() %>%
  kable() %>%
  kable_styling()
```

### Fix Missing Values

There are `r df %>% filter(is.na(CAR_AGE)) %>% nrow()` observations where the `CAR_AGE` variable is missing, `r df %>% filter(is.na(YOJ)) %>% nrow()` observations where variable `YOJ` is missing, `r df %>% filter(is.na(AGE)) %>% nrow() ` observations where the variable `AGE` is missing, `r df %>% filter(is.na(INCOME)) %>% nrow() ` observations where the variable `INCOME` is missing, and `r df %>% filter(is.na(HOME_VAL)) %>% nrow() ` observations where the variable `HOME_VAL` is missing.  There are `r nrow(df) - nrow(na.omit(df))`, or `r round(((nrow(df) - nrow(na.omit(df))) / nrow(df)) * 100)`% of the observations missing varables.

### Feature Creation

We will create a log transformed income and home value feature.  We will also create an average claim amount that will hopefully track better with the `TARGET_AMT` variable.

```{r}
feature_creation <- function(d){
  d %>%
    rowwise() %>%
    mutate(LOG_INCOME = log(INCOME + 1),
           LOG_HOME_VAL = log(HOME_VAL + 1),
           AVG_CLAIM = ifelse(CLM_FREQ > 0, OLDCLAIM / CLM_FREQ, 0)) %>%
    ungroup()
}

df <- feature_creation(df)
evaluation <- feature_creation(evaluation)
```

### Creating Training/Test Data Sets

Now that we have a complete data set we will split the data into a training (`train`) and test set (`test`). We'll use a 70-30 split between train and test, respectively.

```{r}
set.seed(42)
train_index <- createDataPartition(df$TARGET_AMT, p = .7, list = FALSE, times = 1)
train <- df[train_index,]
test <- df[-train_index,]
```

There are `r sum(train$TARGET_FLAG)` out of `r nrow(train)` records in the training data set that have been in an accident.  We want to correct the imballance in the dataset by over sampling this group so our model will do a better job identifying this minority group.

```{r}
set.seed(42)
minority <- nrow(train[train$TARGET_FLAG == 1,])
majority <- nrow(train[train$TARGET_FLAG == 0,])
diff <- majority - minority
minority_index <- train[train$TARGET_FLAG == 1,]$INDEX
over_sample_train <- data.frame(INDEX = sample(minority_index, diff, TRUE)) %>%
  merge(train, .) %>%
  bind_rows(train)
```

The over sampled data frame has `r nrow(over_sample_train)` records, and as you can see in the following figure is now balanced:

```{r, echo=FALSE}
over_sample_train %>% 
  mutate(TARGET_FLAG = as.factor(TARGET_FLAG)) %>%
  ggplot(aes(x=TARGET_FLAG, fill=TARGET_FLAG)) +
  geom_bar() + scale_y_continuous() + scale_fill_brewer(palette="Set1") +
  theme_light() +
  theme(legend.position = "none") +
  labs(x="TARGET_FLAG", y="# Observations")
```