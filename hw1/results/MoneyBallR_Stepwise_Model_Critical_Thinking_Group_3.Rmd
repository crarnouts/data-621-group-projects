---
title: "MoneyBallR_Modeling"
author: "Critical Thinking Group 3"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
  html_document:
    df_print: paged
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
```


#Load in the Data
```{r}
library(tidyverse)
library(tidyverse)
library(kableExtra)
library(corrplot)
library(caret)
library(DMwR)
df_train <- read.csv("https://raw.githubusercontent.com/crarnouts/Data_621/master/moneyball-training-data.csv")
df_train$INDEX <- NULL
df_test <- read.csv("https://raw.githubusercontent.com/crarnouts/Data_621/master/moneyball-evaluation-data.csv")
df_test$INDEX <- NULL
source("https://raw.githubusercontent.com/crarnouts/Data_605_Final/master/RandomForestNulls_testing.R")
colnames(df_train) <- sub("TEAM_", "", colnames(df_train))
colnames(df_test) <- sub("TEAM_", "", colnames(df_test))

```

#Missing Variables 
```{r}
df_train %>% 
  gather(variable, value) %>%
  filter(is.na(value)) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(df_train) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  rename(`Variable Missing Data` = variable,
         `Number of Records` = n,
         `Share of Total` = percent) %>%
  kable() %>%
  kable_styling()
```




# See if we can impute some misssing values Using a Random Forest
```{r}


df_train[which(df_train$TARGET_WINS == 0), "TARGET_WINS"] <- round(mean(df_train$TARGET_WINS), 0)

# Change 0's to NA so they too can be imputed
df_train <- df_train %>%
  mutate(BATTING_SO = ifelse(BATTING_SO == 0, NA, BATTING_SO))
knn <- df_train %>% knnImputation()
impute_me <- is.na(df_train$BATTING_SO)
df_train[impute_me,"BATTING_SO"] <- knn[impute_me,"BATTING_SO"] 

impute_me <- is.na(df_train$BASERUN_SB)
df_train[impute_me,"BASERUN_SB"] <- knn[impute_me,"BASERUN_SB"] 

impute_me <- is.na(df_train$BASERUN_CS)
df_train[impute_me,"BASERUN_CS"] <- knn[impute_me,"BASERUN_CS"]

impute_me <- is.na(df_train$BATTING_HBP)
df_train[impute_me,"BATTING_HBP"] <- knn[impute_me,"BATTING_HBP"] 

df_train[which(df_train$PITCHING_SO > 5346),"PITCHING_SO"] <- NA
impute_me <- is.na(df_train$PITCHING_SO)
df_train[impute_me,"PITCHING_SO"] <- knn[impute_me,"PITCHING_SO"]

impute_me <- is.na(df_train$FIELDING_DP)
df_train[impute_me,"FIELDING_DP"] <- knn[impute_me,"FIELDING_DP"] 

# Change 0's to NA so they too can be imputed
df_test <- df_test %>%
  mutate(BATTING_SO = ifelse(BATTING_SO == 0, NA, BATTING_SO))
knn <- df_test %>% knnImputation()
impute_me <- is.na(df_test$BATTING_SO)
df_test[impute_me,"BATTING_SO"] <- knn[impute_me,"BATTING_SO"] 

impute_me <- is.na(df_test$BASERUN_SB)
df_test[impute_me,"BASERUN_SB"] <- knn[impute_me,"BASERUN_SB"] 

impute_me <- is.na(df_test$BASERUN_CS)
df_test[impute_me,"BASERUN_CS"] <- knn[impute_me,"BASERUN_CS"]

impute_me <- is.na(df_test$BATTING_HBP)
df_test[impute_me,"BATTING_HBP"] <- knn[impute_me,"BATTING_HBP"] 

df_test[which(df_test$PITCHING_SO > 5346),"PITCHING_SO"] <- NA
impute_me <- is.na(df_test$PITCHING_SO)
df_test[impute_me,"PITCHING_SO"] <- knn[impute_me,"PITCHING_SO"]

impute_me <- is.na(df_test$FIELDING_DP)
df_test[impute_me,"FIELDING_DP"] <- knn[impute_me,"FIELDING_DP"] 



```



#Correlation Matrix
```{r}
na_count <-sapply(df_train, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
library(corrplot)
M <- cor(df_train)
corrplot(M, method = "circle") #plot matrix
library("PerformanceAnalytics")
chart.Correlation(df_train, histogram=TRUE, pch=19)
```

#Feature Creation and Data Cleaning

```{r}

df_train$BATTING_1B <- df_train$BATTING_H - df_train$BATTING_2B - df_train$BATTING_3B - df_train$BATTING_HR
df_test$BATTING_1B <- df_test$BATTING_H - df_test$BATTING_2B - df_test$BATTING_3B - df_test$BATTING_HR

```



#Look at Linear Model with all First Order Predictors
```{r}
train.index1 <- createDataPartition(df_train$TARGET_WINS, p = .7, list = FALSE)
train_data<- df_train[ train.index1,]
hold_out_data  <- df_train[-train.index1,]
model <- lm(TARGET_WINS ~ ., data = train_data)
hold_out_data$Prediction <- predict(model,hold_out_data)
oos_cor <- paste(round(cor(hold_out_data$Prediction,hold_out_data$TARGET_WINS),digits = 2))
summary(model)


first_order_linear <- ggplot(data = hold_out_data, aes(x = Prediction, y = TARGET_WINS)) + 
  geom_point(color='blue') +
  geom_smooth(method = "lm", se = FALSE)+ggtitle(paste("First Order Linear Model with Out of Sample Correlation of: ",oos_cor))

```


#Look at some Decision Trees for Variable Interactions
```{r}
hold_out_data <- RF_with_Nulls(train_data,hold_out_data,"TARGET_WINS",1,10,5,.01,5,1)
```



##Look at Variance Inflation Factors 
```{r}
df_train1 <- df_train
# df_train1$BATTING_H <- NULL
# df_train1$BATTING_SO<- NULL
# df_train1$HR_RATIO <- NULL
# df_train1$BASES_ACQUIRED <- NULL
# df_train1$Hitting_Ratio <- NULL
# df_train1$PITCHING_HR <- NULL
for (i in 3:ncol(df_train1)){
col <- noquote(paste(colnames(df_train1)[i],"~ ."))
model <- lm(col, data = df_train1)
r_squared <- summary(model)$adj.r.squared
VIF <- 1/(1-(r_squared))
print(colnames(df_train1)[i])
print(VIF)
#print(summary(model))
}
```





#Stepwise Regression
```{r}


train.index1 <- createDataPartition(df_train$TARGET_WINS, p = .7, list = FALSE)
train_data<- df_train[ train.index1,]
hold_out_data  <- df_train[-train.index1,]


full_formula <- "TARGET_WINS ~ BATTING_2B + BATTING_3B + BATTING_HR + BATTING_BB + BATTING_SO + BASERUN_SB + BASERUN_CS + PITCHING_H + PITCHING_HR + PITCHING_BB + PITCHING_SO + FIELDING_E + FIELDING_DP + BATTING_1B + I(BATTING_2B^2) + I(BATTING_3B^2) + I(BATTING_HR^2) + I(BATTING_BB^2) + I(BATTING_SO^2) + I(BASERUN_SB^2) + I(BASERUN_CS^2) + I(PITCHING_H^2) + I(PITCHING_HR^2) + I(PITCHING_BB^2) + I(PITCHING_SO^2) + I(FIELDING_E^2) + I(FIELDING_DP^2) + I(BATTING_1B^2) + I(BATTING_2B^3) + I(BATTING_3B^3) + I(BATTING_HR^3) + I(BATTING_BB^3) + I(BATTING_SO^3) + I(BASERUN_SB^3) + I(BASERUN_CS^3) + I(PITCHING_H^3) + I(PITCHING_HR^3) + I(PITCHING_BB^3) + I(PITCHING_SO^3) + I(FIELDING_E^3) + I(FIELDING_DP^3) + I(BATTING_1B^3) + I(BATTING_2B^4) + I(BATTING_3B^4) + I(BATTING_HR^4) + I(BATTING_BB^4) + I(BATTING_SO^4) + I(BASERUN_SB^4) + I(BASERUN_CS^4) + I(PITCHING_H^4) + I(PITCHING_HR^4) + I(PITCHING_BB^4) + I(PITCHING_SO^4) + I(FIELDING_E^4) + I(FIELDING_DP^4) + I(BATTING_1B^4)"

full_model <- lm(full_formula, train_data)
step_back_model <- stepAIC(full_model, direction="backward", trace = F)
poly.call <- summary(step_back_model)$call
final_model <- lm(poly.call[2], train_data)
summary(final_model)


```

#Model Results on the Hold Out Dataset
```{r}


hold_out_data$Prediction <- predict(final_model,hold_out_data)

hold_out_data <- hold_out_data %>% filter(Prediction < 182)%>% filter(Prediction > 0)

cor(hold_out_data$Prediction,hold_out_data$TARGET_WINS)


oos_cor <- paste(round(cor(hold_out_data$Prediction,hold_out_data$TARGET_WINS),digits = 2))

ggplotly(ggplot(hold_out_data, aes(x=Prediction, y=TARGET_WINS, colour = TARGET_WINS)) +
     geom_point(shape=1) + 
  scale_color_gradient2(low = "blue",
                             high = "red", space = "Lab" ) +
  geom_smooth(method = "lm", se = FALSE, colour = "orange")+ggtitle(paste("Polynomial Stepwise Model with Out of Sample Correlation of: ",oos_cor))    # Use hollow circles
 )

ggplotly(first_order_linear)
```





