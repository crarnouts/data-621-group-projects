---
title: "DATA 621 Homework #5"
author: "Critical Thinking Group 3"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 4
    code_folding: "hide"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
library(kableExtra)
library(caret)
library(RColorBrewer)
library(corrplot)
library(gridExtra)
options(scipen = 999)
```

```{r data, echo=FALSE}
df <- read.csv("./data/wine-training-data.csv")
hold_out_data <- read.csv("./data/wine-evaluation-data.csv")
df <- df[,names(df)[2:length(names(df))]] # Drop the INDEX
predictors <- names(df)[2:length(names(df))]
```

## Introduction 

We have been given a dataset with information on `r nrow(df)` commercially available wines.  The variables in the dataset are mostly related to the chemical properties of the wine being sold.  A large wine manufacturer is studying the data in order to predict the number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.  The objective is explore, analyze and build a count regression model to predict the number of cases of wine that will be sold given certain properties of the wine. 

## Data Exploration & Preparation

As previously stated we have `r nrow(df)` observations for developing the model.  The evaluation dataset (which we will set aside for now) consists of `r nrow(hold_out_data)` observations.  We will begin by taking a look at the modeling data:

```{r}
summary(df) %>%
  kable() %>%
  kable_styling()
```

Two things jump out about this dataset.  The first thing is that there are variables with negative values.  These negative values don't make sense in the context of chemical properties of wine.  After all, how can you have negative chlorides?  

Second, there are quite a few records with missing values.  We will need to either impute values or drop the records with incomplete data.  These two issues will need to be corrected in the data.

### Correcting Invalid Values

We will begin by correcting the invalid values.  We will assume the negative values were a data entry issue and a negative value was entered when a positive value was desired.  If these negative values were changed into positive numbers, they would be within the range of plausible values based on the other data.

```{r}
fix_negative_values <- function(df){
  df %>%
    mutate(FixedAcidity = abs(FixedAcidity),
           VolatileAcidity = abs(VolatileAcidity),
           CitricAcid = abs(CitricAcid),
           ResidualSugar = abs(ResidualSugar),
           Chlorides = abs(Chlorides),
           FreeSulfurDioxide = abs(FreeSulfurDioxide),
           TotalSulfurDioxide = abs(TotalSulfurDioxide),
           Sulphates = abs(Sulphates),
           Alcohol = abs(Alcohol))
}
df <- fix_negative_values(df)
hold_out_data <- fix_negative_values(hold_out_data)
```

### Missing Values

The instructions indicate that sometimes, the fact that a variable is missing is actually predictive of the target.  Let's see what we can learn about `TARGET` from the missing values.

```{r}
temp <- df %>%
  select(TARGET, STARS, Alcohol, ResidualSugar, Chlorides, FreeSulfurDioxide, TotalSulfurDioxide, pH, Sulphates) %>%
  gather("variable", "value", -TARGET) %>%
  mutate(na = ifelse(is.na(value), "Yes", "No")) %>%
  group_by(TARGET, na, variable) %>%
  tally() %>%
  ungroup()

 temp <- temp %>%
    group_by(variable, na) %>%
    summarise(total = sum(n)) %>%
    merge(temp) %>%
    mutate(share = n / total)
 
 ggplot(temp, aes(TARGET, share, fill = na)) +
   geom_bar(stat = "identity", position = "dodge") +
   scale_fill_brewer(palette = "Set1") +
   facet_wrap(~variable, ncol = 4) + 
   ylab("Percent of Group")
```
 
We learn that the observations that are missing `STARS` are much more likely to have a zero `TARGET`.  So let's look at how many stars wine with a zero `TARGET` have:

```{r}
df %>%
  filter(TARGET == 0) %>%
  select(STARS) %>%
  na.omit() %>%
  group_by(STARS) %>%
  tally() %>%
  kable() %>%
  kable_styling()
```

Based on this it looks like we should assign 1 for all the missing `STARS`.

There is little to no information encoded in the NAs for `Alcohol`,  `ResidualSugar`, `Chlorides`, `FreeSulfurDioxide`, `TotalSulfurDioxide`, `pH`, and `Sulphates`.  We will impute using the median value.

```{r}
fix_missing_values <- function(df){
  df %>%
    mutate(
      ResidualSugar = ifelse(is.na(ResidualSugar), median(ResidualSugar, na.rm = T), ResidualSugar),
      Chlorides = ifelse(is.na(Chlorides), median(Chlorides, na.rm = T), Chlorides),
      FreeSulfurDioxide = ifelse(is.na(FreeSulfurDioxide), median(FreeSulfurDioxide, na.rm = T), FreeSulfurDioxide),
      TotalSulfurDioxide = ifelse(is.na(TotalSulfurDioxide), median(TotalSulfurDioxide, na.rm = T), TotalSulfurDioxide),
      pH = ifelse(is.na(pH), median(pH, na.rm = T), pH),
      Sulphates = ifelse(is.na(Sulphates), median(Sulphates, na.rm = T), Sulphates),
      Alcohol = ifelse(is.na(Alcohol), median(Alcohol, na.rm = T), Alcohol),
      STARS_imputed = ifelse(is.na(STARS), 1, 0),
      STARS = ifelse(is.na(STARS), 1, STARS)
    )
}
df <- fix_missing_values(df)
hold_out_data <- fix_missing_values(hold_out_data)
```

### Training Test Split

Next we will look at splitting the data into a training and testing set at a standard 70-30 split between train and test:

```{r}
set.seed(42)
train_index <- createDataPartition(df$TARGET, p = .7, list = FALSE, times = 1)
train <- df[train_index,]
test <- df[-train_index,]
```

### Univariate Analysis

#### Response Variable

```{r echo=FALSE, message=FALSE, warning=FALSE}
train %>%
  group_by(TARGET) %>%
  tally() %>%
  ggplot(., aes(x = factor(TARGET), y = n, fill = factor(TARGET))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set1") + 
  theme(legend.position = "none") +
  labs(x="Number of Wine Cases Purchased (TARGET)",y = "Count")
```

In order to model this as a Poisson process the mean should be equal to the variance

```{r}
train %>%
  summarise(mean = mean(TARGET), variance = var(TARGET)) %>%
  kable() %>%
  kable_styling()
```

They are not the same.  The implications of this requirement not being met is the the $\beta$s are correct but the standard errors will be wrong.

#### Predictors

```{r}
dens <- lapply(predictors, FUN=function(var) {
  ggplot(df, aes_string(x = var)) + 
    geom_density(fill = "gray") +
    geom_vline(aes(xintercept = mean(train[, var])), color = "blue", size=1) +
    geom_vline(aes(xintercept = median(train[, var])), color = "red", size=1) +
    geom_vline(aes(xintercept = quantile(train[, var], 0.25)), linetype = "dashed", size = 0.5) + 
    geom_vline(aes(xintercept = quantile(train[, var], 0.75)), linetype = "dashed", size = 0.5)
  })
do.call(grid.arrange, args = c(dens, list(ncol = 3)))
```

Some of the predictors (the chemical composition variables) are right skewed.


### Bivariate Analysis

Now let's examine the correlations between the variables:

```{r}
corrplot.mixed(cor(train))
```

Hmm.  This suggests that the chemical makeup of the wine has little bearing on the number of cases sold.  The label appeal, acidity index value and star rating have the strongest correlation.  This also suggests that it may be worth the effort to do a better job filling in the missing values in the `STARS` variable.

## Model Building & Evaluation

### Setting Up Evaluation

In order to assess the models we will assume that a bottle of wine whosale costs $15.00 and there are 10 bottles in a case.  We will assume that the `TARGET` is the maximum amount that will sell in the market.  Any predictions below the `TARGET` represent potential revenue that is unrealized.  Any predictions over the `TARGET` will not sell and represent a loss of $150.  We will evaluate the model to see if it helps the manufacturers goal of maximizing revenue.

```{r}
evaluate_model <- function(model, test_df, yhat = FALSE){
  price_per_bottle <- 15.00
  bottles_per_case <- 10
  case_price <- price_per_bottle * bottles_per_case
  temp <- data.frame(yhat=c(0:8), TARGET = c(0:8), n=c(0))
  
  if(yhat){
    test_df$yhat <- yhat
  } else {
    test_df$yhat <- round(predict.glm(model, newdata=test_df, type="response"), 0)
  }
  
  test_df <- test_df %>%
    group_by(yhat, TARGET) %>%
    tally() %>%
    mutate(accuracy = ifelse(yhat > TARGET, "Over", ifelse(yhat < TARGET, "Under", "Accurate"))) %>%
    mutate(off_by = abs(yhat - TARGET)) %>%
    mutate(revenue = ifelse(off_by == 0, 1, -1) * n * case_price)
  
  rev_df <- test_df %>%
    group_by(accuracy) %>%
    summarise(revenue = sum(revenue)) %>%
    spread(accuracy, revenue)
  
  total_rev <- sum(test_df$revenue)
  
  results <- test_df %>%
    group_by(accuracy) %>%
    summarise(n = sum(n))
  
  confusion_matrix <- test_df %>%
    bind_rows(temp) %>%
    group_by(yhat, TARGET) %>%
    summarise(n = sum(n)) %>%
    spread(TARGET, n, fill = 0)
  
  return(list("total_rev" = total_rev, "rev_df" = rev_df, "confusion_matrix" = confusion_matrix, "results" = results))
}
```

### Chemical Property Model

We will begin by first constructing a count regression model based on the chemical properties of the wine.  So we will be excluding the label, star rating and the acid index as it is a weighted average of the acidity variables.  Based on our bivariate analysis we would not expect this model to preform well.  Since the mean is not equal to the variance we will be using the quasi-Poisson model.

```{r}
train1 <- train %>%
  select(-LabelAppeal, -AcidIndex, -STARS, -STARS_imputed)
model1 <- glm(TARGET ~ ., family = quasipoisson, train1)
summary(model1)
model1_results <- evaluate_model(model1, test)
```

The following is a confusion matrix like examination of the model with the predicted cases going down the rows and the actual cases going across the columns.

```{r}
model1_results$confusion_matrix %>% 
  kable() %>% 
  kable_styling()
```

The model is only accurate `r temp <- model1_results$results %>% filter(accuracy == "Accurate"); temp$n` times.  It overestimates `r temp <- model1_results$results %>% filter(accuracy == "Over"); temp$n` times and underestimates `r temp <- model1_results$results %>% filter(accuracy == "Under"); temp$n` times.  The following shows the revenue gained or lost due to the model's predictions:

```{r}
model1_results$rev_df %>%
  kable() %>%
  kable_styling()
```

This model would result in $`r model1_results$total_rev` in revenue.  The company would loose a lot of money if the model was implemented.  

### Second Chemical Property Model

We will try one more chemical property model but only select the variables that were statistically significant in the preious model (`FixedAcidity`, `VolatileAcidity` and `Alcohol`).

```{r}
model2 <- glm(TARGET ~ FixedAcidity + VolatileAcidity + Alcohol, family = quasipoisson, train)
summary(model2)
model2_results <- evaluate_model(model2, test)
```

This model would generate $`r model2_results$total_rev` in revenue.  This is a slight improvement but is still a horible model.  Building a model based off of the chemical properties does not seem like a good solution.  Let's turn our attention to the other variables with stronger correlations.

### Preceived Quality Model

This model relies on the consumer preception of quality based on the label, and the star ratings of the experts.

```{r}
model3 <- glm(TARGET ~ LabelAppeal + STARS, family = quasipoisson, train)
summary(model3)
model3_results <- evaluate_model(model3, test)
```

Here is a confusion matrix for this model:

```{r}
model3_results$confusion_matrix %>% 
  kable() %>% 
  kable_styling()
```


The model is only accurate `r temp <- model3_results$results %>% filter(accuracy == "Accurate"); temp$n` times.  It overestimates `r temp <- model3_results$results %>% filter(accuracy == "Over"); temp$n` times and underestimates `r temp <- model3_results$results %>% filter(accuracy == "Under"); temp$n` times.  This is an improvement from just the chemical property models, however there is still a lot of error.  The following shows the revenue gained or lost due to the model's predictions:

```{r}
model3_results$rev_df %>%
  kable() %>%
  kable_styling()
```

This model would result in $`r model3_results$total_rev` in revenue.


### Perceived Quality Plus Model

We will begin with the preceeding model but add in the Acid Index and the flag if the STARS was imputed.

```{r}
model4 <- glm(TARGET ~ LabelAppeal + STARS + AcidIndex + STARS_imputed, family = quasipoisson, train)
summary(model4)
model4_results <- evaluate_model(model4, test)
```

Let's see how the predictions line up with the reality:

```{r}
model4_results$confusion_matrix %>% 
  kable() %>% 
  kable_styling()
```

The model is accurate `r temp <- model4_results$results %>% filter(accuracy == "Accurate"); temp$n` times.  It overestimates `r temp <- model4_results$results %>% filter(accuracy == "Over"); temp$n` times and underestimates `r temp <- model4_results$results %>% filter(accuracy == "Under"); temp$n` times.  The following shows the revenue gained or lost due to the model's predictions:

```{r}
model4_results$rev_df %>%
  kable() %>%
  kable_styling()
```

This model would result in $`r model4_results$total_rev` in revenue.  It is the best model so far but it still would loose a lot of money because it overestimates the number of cases to be sold.  

There are no zero predictions in this model which is not accurate.  We will try to address this in our last model

### Adjusted Perceived Quality Plus Model

We will start with the predictions from preceived quality plus model.  We will then manually override the the predictions that have the stars filled in with a predicted zero.

```{r}
temp <- test
temp$yhat <- round(predict.glm(model4, newdata=temp, type="response"), 0)
temp <- temp %>%
  mutate(yhat = ifelse(STARS_imputed == 1, 0, yhat))
model5_results <- evaluate_model(model4, test, temp$yhat)
```

```{r}
model5_results$confusion_matrix %>% 
  kable() %>% 
  kable_styling()
```

```{r}
model5_results$rev_df %>%
  kable() %>%
  kable_styling()
```

